{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01d0b74-5942-4e80-96b4-8cbb96897093",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5f52aa-0b04-4553-9550-1927d409d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numerical analysis\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "# to store and process in a dataframe\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Visualizations, for ploting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# image processing\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# advanced ploting\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5485d8f3-4714-4f5a-a288-fd90b3bce1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian Ashiali\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# PyTorch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d\n",
    "from torch.nn import Module, Softmax, BatchNorm2d, Dropout\n",
    "\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Image manipulations\n",
    "from PIL import Image\n",
    "#from libjpeg import decode\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Timing utility\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Printing out all outputs\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# file operations\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "from os import walk\n",
    "\n",
    "# to list files\n",
    "import glob\n",
    "\n",
    "print(os.listdir(\"ECG_data/\"))\n",
    "\n",
    "# current working directory\n",
    "folder_path = os.listdir(\"ECG_data/\")\n",
    "folder_path\n",
    "\n",
    "#class_folders= os.listdir(folder_path)\n",
    "#class_folders\n",
    "\n",
    "#for class_folder in class_folders:\n",
    "#   class_path= os.path.join(folder_path, class_folder)\n",
    "#   num_images = len(os.listdir(class_path))\n",
    "#    print(f'Number of images in {class_folder}:{num_images}')\n",
    "\n",
    "# no. of files\n",
    "\n",
    "def list_files(startpath):\n",
    "    \n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        \n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        \n",
    "        indent = ' ' * 4 * (level)\n",
    "        \n",
    "        print('{}{}'.format(indent, os.path.basename(root)), '-', len(os.listdir(root)))\n",
    "        \n",
    "folder = 'ECG_data/'\n",
    "list_files(folder)\n",
    "\n",
    "folder = 'ECG_data/'\n",
    "list_files(folder)\n",
    "\n",
    "# list of files in the dataset /input/ecg-images/MITBIH_img\n",
    "\n",
    "os.listdir('ECG_data/test/')\n",
    "\n",
    "# Classes in the data\n",
    "\n",
    "ECG_list = os.listdir('ECG_data/test/')\n",
    "\n",
    "n_classes = len(ECG_list)\n",
    "\n",
    "print(f'There are {n_classes} different classes.')\n",
    "\n",
    "ECG_list\n",
    "\n",
    "classes = ('S', 'V', 'Q', 'N', 'F', 'M')\n",
    "\n",
    "#Count Number of Files in the MITBIH_img Folder\n",
    "\n",
    "N_imgs = os.listdir('ECG_data/test/N/')\n",
    "print('# of Normal beats: ',len(N_imgs))\n",
    "\n",
    "F_imgs = os.listdir('ECG_data/test/F/')\n",
    "print('# of Fusion beats: ',len(F_imgs))\n",
    "\n",
    "Q_imgs = os.listdir('ECG_data/test/Q/')\n",
    "print('# of Unknown beats: ',len(Q_imgs))\n",
    "\n",
    "V_imgs = os.listdir('ECG_data/test/V/')\n",
    "print('# of Ventricular ectopic beats: ',len(V_imgs))\n",
    "\n",
    "S_imgs = os.listdir('ECG_data/test/S/')\n",
    "print('# of Supraventricular ectopic beats: ',len(S_imgs))\n",
    "\n",
    "M_imgs = os.listdir('ECG_data/test/M/')\n",
    "print('# of M-Research ectopic beats: ',len(M_imgs))\n",
    "\n",
    "#print(N_dir)\n",
    "print(N_imgs[0])\n",
    "\n",
    "#EDA\n",
    "\n",
    "def imshow(image):\n",
    "    \"\"\"Display image\"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "image = mpimg.imread(os.path.join('ECG_data/test/N/', N_imgs[0]))\n",
    "\n",
    "imshow(image)\n",
    "\n",
    "print(image.shape)\n",
    "print(type(image))\n",
    "\n",
    "#Show Images From Each Folder\n",
    "\n",
    "# Define a function which will plot several images\n",
    "\n",
    "def image_shows(folder, number_of_images):\n",
    "    \n",
    "    n=number_of_images;\n",
    "    \n",
    "    folder_list = os.listdir(folder)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows = 1, ncols=n, figsize=(20, 10))\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        print(os.path.join(folder, folder_list[i]))\n",
    "        \n",
    "        image = mpimg.imread(os.path.join(folder, folder_list[i]));\n",
    "        \n",
    "        axes[i].imshow(image);\n",
    "        \n",
    "# Examples of N\n",
    "\n",
    "image_shows(folder = 'ECG_data/test/N/', number_of_images = 6)\n",
    "\n",
    "# Examples of S\n",
    "\n",
    "image_shows(folder = 'ECG_data/test/S/', number_of_images = 6)\n",
    "\n",
    "# Examples of Q\n",
    "\n",
    "image_shows(folder = 'ECG_data/test/Q/', number_of_images = 6)\n",
    "\n",
    "# Examples of M\n",
    "\n",
    "image_shows(folder = 'ECG_data/test/M/', number_of_images = 6)\n",
    "\n",
    "# Examples of V\n",
    "\n",
    "image_shows(folder = 'ECG_data/test/V/', number_of_images = 6)\n",
    "\n",
    "# Examples of F\n",
    "\n",
    "image_shows(folder = 'ECG_data/test/F/', number_of_images = 6)\n",
    "\n",
    "#To see 3 channels I plot figures with cv 2 package\n",
    "\n",
    "#import cv2\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "\n",
    "import cv2\n",
    "\n",
    "imgcv = cv2.imread(os.path.join('ECG_data/test/N/', N_imgs[0]))\n",
    "plt.imshow(imgcv)\n",
    "plt.show();\n",
    "\n",
    "imgcv.shape\n",
    "\n",
    "b = imgcv.copy()\n",
    "# set green and red channels to 0\n",
    "b[:, :, 1] = 0\n",
    "b[:, :, 2] = 0\n",
    "\n",
    "\n",
    "g = imgcv.copy()\n",
    "# set blue and red channels to 0\n",
    "g[:, :, 0] = 0\n",
    "g[:, :, 2] = 0\n",
    "\n",
    "r = imgcv.copy()\n",
    "# set blue and green channels to 0\n",
    "r[:, :, 0] = 0\n",
    "r[:, :, 1] = 0\n",
    "\n",
    "#plot rgb\n",
    "# plot data\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "plot_1 = plt.subplot(131)\n",
    "plot_1.imshow(r);\n",
    "\n",
    "#plt.subplot(131).imshow(b);\n",
    "\n",
    "plot_2 = plt.subplot(132, sharex=plot_1, sharey=plot_1)\n",
    "plt.setp(plot_2.get_yticklabels(), visible=False);\n",
    "plot_2.imshow(b);\n",
    "\n",
    "plot_3 = plt.subplot(133, sharex=plot_1, sharey=plot_1)\n",
    "plt.setp(plot_3.get_yticklabels(), visible=False);\n",
    "plot_3.imshow(g);\n",
    "\n",
    "plt.show();\n",
    "\n",
    "for root, dirs, files in os.walk('ECG_data/'):\n",
    "    print(root)\n",
    "    #So, as the code runs, it will print the paths of all directories\n",
    "    #within the '/ecg/' directory and its subdirectories.\n",
    "    \n",
    "folder = 'ECG_data/'\n",
    "list_files(folder)\n",
    "\n",
    "N_imgs       = len(os.listdir('ECG_data/train/N/'))\n",
    "N_train_imgs = len(os.listdir('ECG_data/train/N/'))\n",
    "N_test_imgs  = len(os.listdir('ECG_data/test/N/'))\n",
    "print('number of N images at the original file: ', N_imgs)\n",
    "print('total number of train and test picts:    ', N_train_imgs + N_test_imgs)\n",
    "\n",
    "S_imgs       = len(os.listdir('ECG_data/train/S/'))\n",
    "S_train_imgs = len(os.listdir('ECG_data/train/S/'))\n",
    "S_test_imgs  = len(os.listdir('ECG_data/test/S/'))\n",
    "print('number of S images at the original file: ', S_imgs)\n",
    "print('total number of train and test picts:    ', S_train_imgs + S_test_imgs)\n",
    "\n",
    "F_imgs       = len(os.listdir('ECG_data/train/F/'))\n",
    "F_train_imgs = len(os.listdir('ECG_data/train/F/'))\n",
    "F_test_imgs  = len(os.listdir('ECG_data/test/F/'))\n",
    "print('number of F images at the original file: ', F_imgs)\n",
    "print('total number of train and test picts:    ', F_train_imgs + F_test_imgs)\n",
    "\n",
    "V_imgs       = len(os.listdir('ECG_data/train/V/'))\n",
    "V_train_imgs = len(os.listdir('ECG_data/train/V/'))\n",
    "V_test_imgs  = len(os.listdir('ECG_data/test/V/'))\n",
    "print('number of V images at the original file: ', V_imgs)\n",
    "print('total number of train and test picts:    ', V_train_imgs + V_test_imgs)\n",
    "\n",
    "M_imgs       = len(os.listdir('ECG_data/train/M/'))\n",
    "M_train_imgs = len(os.listdir('ECG_data/train/M/'))\n",
    "M_test_imgs  = len(os.listdir('ECG_data/test/M/'))\n",
    "print('number of M images at the original file: ', M_imgs)\n",
    "print('total number of train and test picts:    ', M_train_imgs + M_test_imgs)\n",
    "\n",
    "Q_imgs       = len(os.listdir('ECG_data/train/Q/'))\n",
    "Q_train_imgs = len(os.listdir('ECG_data/train/Q/'))\n",
    "Q_test_imgs  = len(os.listdir('ECG_data/test/Q/'))\n",
    "print('number of Q images at the original file: ', Q_imgs)\n",
    "print('total number of train and test picts:    ', Q_train_imgs + Q_test_imgs)\n",
    "\n",
    "#Lets load images with datasets.ImageFolder function and than read and plot\n",
    "#Set Data Loader\n",
    "TRAIN_PATH        = 'ECG_data/train/'\n",
    "\n",
    "transform         = transforms.Compose(\n",
    "                                       [transforms.Resize([120,120]),\n",
    "                                        transforms.Grayscale(), \n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5), (0.5))\n",
    "                                       ])\n",
    "  \n",
    "train_data_set    = datasets.ImageFolder(root=TRAIN_PATH, transform=transform)\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "train_data_loader = DataLoader(train_data_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "TEST_PATH        = 'ECG_data/test/'\n",
    "  \n",
    "test_data_set    = datasets.ImageFolder(root=TEST_PATH, transform=transform)\n",
    "\n",
    "test_data_loader = DataLoader(test_data_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Run this to test your data loader\n",
    "\n",
    "images, labels = next(iter(train_data_loader))\n",
    "\n",
    "print(type(images))\n",
    "\n",
    "\n",
    "print(images.size())\n",
    "\n",
    "print(\"\")\n",
    "print(\"Batch Size:   \",images.size()[0])\n",
    "print(\"Channel Size: \",images.size()[1])\n",
    "print(\"Image Height: \",images.size()[2])\n",
    "print(\"Image Width:  \",images.size()[3])\n",
    "\n",
    "#The batch size is 32, image size is reduced to 120*120 and we need only one channel(Gray Scale).\n",
    "\n",
    "def imshow_tensor(image, ax=None, title=None, normalize=True):\n",
    "    \n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.5])\n",
    "        std = np.array([0.5])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax\n",
    "\n",
    "#Plot one Batch of Files from Dataloader\n",
    "\n",
    "# show images\n",
    "\n",
    "ncol = 8;\n",
    "\n",
    "imshow_tensor(torchvision.utils.make_grid(images,nrow = ncol));\n",
    "\n",
    "# print labels\n",
    "\n",
    "classes = ('N', 'Q', 'F', 'S', 'V','M')\n",
    "\n",
    "nrow = batch_size/ncol;\n",
    "\n",
    "for row in range(int(nrow)):\n",
    "    \n",
    "    print(' '.join('%5s' % classes[labels[(row*ncol)+j]] for j in range(ncol)))\n",
    "    \n",
    "#Building Convolutional Neural Networks\n",
    "\n",
    "#First CNN Model\n",
    "\n",
    "# CNN Architect\n",
    "#Enhanced convolutional Neural Netwwork\n",
    "\n",
    "#class EnhancedConvNet(nn.Module):\n",
    "    \n",
    "    #def __init__(self):\n",
    "        #first convolution Block\n",
    "        \n",
    "       # super(EnhancedConvNet, self).__init__()\n",
    "\n",
    "        #self.conv1  = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "       # self.bn1 = nn.BatchNorm2d(8)\n",
    "        \n",
    "        #self.relu1    = nn.ReLU(inplace=True)\n",
    "        \n",
    "        #self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        #second convolution Block\n",
    "        \n",
    "\n",
    "       # self.conv2  = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "       # self.bn2 = nn.BatchNorm2d(16)\n",
    "        \n",
    "       # self.relu2    = nn.ReLU(inplace=True)\n",
    "        \n",
    "       # self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # out_channels = 8, number of classes = 6\n",
    "        \n",
    "        # image width = 120, image height = 120 after two maxpooling 120 -> 60 -> 30\n",
    "        \n",
    "        #fully connected layer\n",
    "        \n",
    "        #self.fc = nn.Linear(16 * 30 * 30, 6) # adjust the dimesnsions according to the input image size\n",
    "        \n",
    "    # Defining the forward pass\n",
    "   # def forward(self, x):\n",
    "        \n",
    "      #  x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        \n",
    "       # x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        #x= x.view(x.size(0),-1) # flatten the output\n",
    "        \n",
    "        #x= self.fc(x)\n",
    "        \n",
    "        #return x\n",
    "    \n",
    "    #initialize the model\n",
    "   # model = EnhancedConvNet()\n",
    "    #model\n",
    "        \n",
    "        \n",
    "        #out = self.layer_1(x)\n",
    "        \n",
    "        #out = self.relu1(out)\n",
    "        \n",
    "        #out = self.maxpool1(out)\n",
    "        \n",
    "        \n",
    "        #out = self.layer_2(out)\n",
    "        \n",
    "        #out = self.relu2(out)\n",
    "        \n",
    "        #out = self.maxpool2(out)\n",
    "        \n",
    "        \n",
    "        #out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        #out = self.drop_out(out)\n",
    "        \n",
    "        #out = self.fc1(out)\n",
    "        \n",
    "        #return out\n",
    "    \n",
    "# Define Model\n",
    "\n",
    "#model_1 = ConvNet_1()\n",
    "\n",
    "#print(model_1)\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# CNN Architect\n",
    "# Enhanced convolutional Neural Network\n",
    "\n",
    "class EnhancedConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(EnhancedConvNet, self).__init__()\n",
    "\n",
    "        # First convolution Block\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Second convolution Block\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "\n",
    "        # Out_channels = 16, number of classes = 6\n",
    "        # Image width = 120, image height = 120 after two maxpooling 120 -> 60 -> 30\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(16 * 30 * 30, 6)  # Adjust the dimensions according to the input image size\n",
    "    \n",
    "    # Defining the forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = EnhancedConvNet()\n",
    "\n",
    "# focal loss implementation\n",
    "\n",
    "# focal loss implemention\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha= 1, gamma= 2, logits= False, reduce = True ):\n",
    "        super(FocalLoss,self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "        \n",
    "    def forward(self,inputs, target):\n",
    "        if self.logits:\n",
    "            #apply sigmoid activation if using logits\n",
    "            inputs = torch.sigmoid(inputs)\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, target, reduction='none')\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, target, reduction= 'none')\n",
    "            \n",
    "        pt = torch.exp(-BCE_loss) #Prevents nans when loss is zero\n",
    "        F_loss = self.alpha* (1-pt)**self.gamma * BCE_loss\n",
    "        \n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "#one_hot_labels = F.one_hot(labels, num_classes=6).float()\n",
    "        \n",
    "# Initialize Focal Loss\n",
    "criterion = FocalLoss()\n",
    "\n",
    "# Define Criterion\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define Optimizer\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Whether to train on a gpu and Number of gpus\n",
    "\n",
    "if cuda.is_available(): \n",
    "    \n",
    "    print(f'{cuda.device_count()} number of gpus are detected and available.')\n",
    "    \n",
    "else:\n",
    "        \n",
    "    print(f'Train on gpu is not available')\n",
    "        \n",
    "\n",
    "#Train Our First Model\n",
    "\n",
    "# ... (your model and FocalLoss definitions)\n",
    "\n",
    "# Initialize Focal Loss\n",
    "#criterion = FocalLoss()\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# This part is working\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    print(f'Model is started training on {cuda.device_count()} number of gpus.')\n",
    "    print(\"Device is cuda\")\n",
    "else:\n",
    "    print(\"Device is cpu and model is started training.\")\n",
    "\n",
    "total_step = len(train_data_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "all_con_mat = torch.zeros([num_epochs, 6, 6], dtype=torch.int32, device=device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    con_mat = torch.zeros([6, 6], dtype=torch.int32, device=device)\n",
    "\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "# forward pass\n",
    "        outputs = model(inputs)\n",
    "    #apply sigmoid activation for BCEWithLogitsLoss\n",
    "        outputs_sigmoid = torch.sigmoid(outputs)\n",
    "        # Convert labels to one-hot encoding\n",
    "        one_hot_labels = F.one_hot(labels, num_classes=6).float()\n",
    "    # calculate loss\n",
    "        loss = criterion(outputs_sigmoid, labels)\n",
    "        # backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        for element in range(total):\n",
    "            con_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n",
    "\n",
    "        if (i + 1) % 300 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))\n",
    "    print(con_mat)\n",
    "    all_con_mat[epoch] = con_mat\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(acc_list)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# SUM FOR EACH COLUMN\n",
    "\n",
    "# M N Q S V F\n",
    "\n",
    "print(torch.sum(con_mat, dim=0))\n",
    "\n",
    "folder = 'ECG_data/'\n",
    "list_files(folder)\n",
    "\n",
    "# RECALL\n",
    "\n",
    "# PRECISION\n",
    "\n",
    "# F1-score = 2 × (precision × recall)/(precision + recall)\n",
    "\n",
    "class_list = ['M','N', 'Q', 'S', 'V', 'F']\n",
    "\n",
    "f1_score_list=[0,0,0,0,0,0]\n",
    "\n",
    "precision_list=[0,0,0,0,0,0]\n",
    "\n",
    "recall_list=[0,0,0,0,0,0]\n",
    "\n",
    "delta = 0.0000000000001\n",
    "\n",
    "for i in range(torch.sum(con_mat, dim=0).size(0)): \n",
    "    \n",
    "    recall_list[i] = con_mat[i][i].item()/(torch.sum(con_mat, dim=0)[i].item()+delta)\n",
    "    \n",
    "    precision_list[i] = con_mat[i][i].item()/(torch.sum(con_mat, dim=1)[i].item()+delta)\n",
    "    \n",
    "    f1_score_list[i] = 2 * precision_list[i]*recall_list[i]/(precision_list[i]+recall_list[i]+delta)\n",
    "    \n",
    "    print('class: {:<2},total number of class: {:>6}, Correctly predicted: {:>6}, Recall: {:.2f}%, Precision: {:.2f}%, F1-Score: {:.2f}%'\n",
    "          \n",
    "                  .format(class_list[i],\n",
    "                          torch.sum(con_mat, dim=0)[i].item(),\n",
    "                          con_mat[i][i].item(), \n",
    "                          recall_list[i],\n",
    "                          precision_list[i],\n",
    "                          f1_score_list[i]\n",
    "                         ))\n",
    "    \n",
    "    # This part is working\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    \n",
    "    MODEL = model_1.cuda()\n",
    "    CRITERION = criterion.cuda()\n",
    "    print(\"cuda\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    MODEL = model_1\n",
    "    CRITERION = criterion\n",
    "    print(\"cpu\")\n",
    "\n",
    "# Train the model\n",
    "\n",
    "total_step = len(train_data_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "class_list = ['M','N', 'Q', 'S', 'V', 'F']\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "all_con_mat = torch.zeros([num_epochs, 6, 6], dtype=torch.int32, device=device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    f1_score_list=[0,0,0,0,0,0]\n",
    "\n",
    "    precision_list=[0,0,0,0,0,0]\n",
    "\n",
    "    recall_list=[0,0,0,0,0,0]\n",
    "    \n",
    "    delta = 0.0000000000001 \n",
    "    \n",
    "    # define empty tensor 5*5 beginning of every epoch\n",
    "    # tensor [row,column]\n",
    "    con_mat = torch.zeros([6, 6], dtype=torch.int32, device=device)\n",
    "    \n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # optimization\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward to get output\n",
    "        outputs = MODEL(inputs)\n",
    "        # Calculate Loss\n",
    "        loss = CRITERION(outputs, labels)\n",
    "        # Backward propagation\n",
    "        loss.backward()\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Store loss\n",
    "        loss_list.append(loss.item())\n",
    "    \n",
    "        # Calculate labels size\n",
    "        total = labels.size(0)\n",
    "        \n",
    "        # Outputs.data has dimension batch size * 5\n",
    "        # torch.max returns the max value of elements(_) and their indices(predicted) in the tensor array\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Calculate total number of correct labels \n",
    "        correct = (predicted == labels).sum().item()\n",
    "        \n",
    "        # Store accuracy\n",
    "        acc_list.append(correct / total)\n",
    "        \n",
    "        for element in range(total):\n",
    "            \n",
    "            # con_mat[row,column]\n",
    "            # con_mat[predictions, actual]\n",
    "            con_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n",
    "\n",
    "        if (i + 1) % 300 == 0:                             # every 300 mini-batches...\n",
    "            \n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  \n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))\n",
    "    print(con_mat)\n",
    "            \n",
    "    all_con_mat[epoch] = con_mat\n",
    "    \n",
    "    # Print Confusion Matrix\n",
    "    \n",
    "    for i in range(torch.sum(con_mat, dim=0).size(0)): \n",
    "    \n",
    "        recall_list[i] = con_mat[i][i].item()/(torch.sum(con_mat, dim=0)[i].item()+delta)\n",
    "    \n",
    "        precision_list[i] = con_mat[i][i].item()/(torch.sum(con_mat, dim=1)[i].item()+delta)\n",
    "    \n",
    "        f1_score_list[i] = 2 * precision_list[i]*recall_list[i]/(precision_list[i]+recall_list[i]+delta)\n",
    "        \n",
    "    \n",
    "        print('class name: {}, total number of class: {:>6}, Correctly predicted: {:>6}, Recall: {:.2f}%, Precision: {:.2f}%, F1-Score: {:.2f}%'\n",
    "          \n",
    "                  .format(class_list[i],\n",
    "                          torch.sum(con_mat, dim=0)[i].item(),\n",
    "                          con_mat[i][i].item(), \n",
    "                          recall_list[i],\n",
    "                          precision_list[i],\n",
    "                          f1_score_list[i]\n",
    "                         ))\n",
    "        \n",
    "print('Finished Training')\n",
    "\n",
    "plt.plot(loss_list);\n",
    "plt.show();\n",
    "\n",
    "plt.plot(acc_list);\n",
    "plt.show();\n",
    "\n",
    "all_con_mat\n",
    "\n",
    "#Check Trained 1. Model on the Test Data\n",
    "confusion_mat = torch.zeros([6, 6], dtype=torch.int32, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for data in test_data_loader:\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = MODEL(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total = labels.size(0)\n",
    "        \n",
    "        # Calculate total number of correct labels \n",
    "        correct = (predicted == labels).sum().item()\n",
    "        \n",
    "        for element in range(total):\n",
    "            \n",
    "            # confusion_mat[row,column]\n",
    "            # confusion_mat[predictions, actual]\n",
    "            confusion_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n",
    "\n",
    "    print(confusion_mat)\n",
    "    \n",
    "\n",
    "class_list = ['M','N', 'Q', 'S', 'V', 'F']\n",
    "\n",
    "f1_score_list=[0,0,0,0,0,0]\n",
    "\n",
    "precision_list=[0,0,0,0,0,0]\n",
    "\n",
    "recall_list=[0,0,0,0,0,0]\n",
    "    \n",
    "delta = 0.0000000000001 \n",
    "\n",
    "\n",
    "for i in range(torch.sum(confusion_mat, dim=0).size(0)): \n",
    "    \n",
    "        recall_list[i] = confusion_mat[i][i].item()/(torch.sum(confusion_mat, dim=0)[i].item()+delta)\n",
    "    \n",
    "        precision_list[i] = confusion_mat[i][i].item()/(torch.sum(confusion_mat, dim=1)[i].item()+delta)\n",
    "    \n",
    "        f1_score_list[i] = 2 * precision_list[i]*recall_list[i]/(precision_list[i]+recall_list[i]+delta)\n",
    "        \n",
    "        print('class name: {}, total number of class: {:>6}, Correctly predicted: {:>6}, Recall: {:.2f}%, Precision: {:.2f}%, F1-Score: {:.2f}%'\n",
    "          \n",
    "                  .format(class_list[i],\n",
    "                          torch.sum(confusion_mat, dim=0)[i].item(),\n",
    "                          confusion_mat[i][i].item(), \n",
    "                          recall_list[i],\n",
    "                          precision_list[i],\n",
    "                          f1_score_list[i]\n",
    "                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36071fdd-8103-414f-9a5c-b9af97c1565d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
